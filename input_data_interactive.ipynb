{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169392c235ba55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:27:00.025792Z",
     "start_time": "2024-07-15T12:26:59.040622Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "# Create the folder\n",
    "os.makedirs(\"Data/Plots\", exist_ok=True)\n",
    "\n",
    "reload(utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb323ca0c7dc7c7a",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbf5d803b28b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:27:26.475937Z",
     "start_time": "2024-07-15T12:27:26.461747Z"
    }
   },
   "outputs": [],
   "source": [
    "earth_radius_km = 6371  # km\n",
    "grid_size_km = 250  # Size of the square grid in km\n",
    "cell_size_km = 5  #Cell size in km\n",
    "cell_size_rads = cell_size_km / earth_radius_km  # Cell size in radians\n",
    "cell_size_degs = cell_size_rads * 180 / np.pi\n",
    "scale_factor = 1e6  # Scale factor for the coordinates from km to mm\n",
    "num_cells = int(grid_size_km / cell_size_km)  # number of cells in the lateral direction\n",
    "#min_stations_inside = 3  # minimal number of stations inside the grid\n",
    "\n",
    "sigma_softlabels = 1  # sigma for the gaussian smoothing of the labels, expressed in number of cell sizes\n",
    "sigma_interpolation = 8  ## expressed in number of cell sizes\n",
    "sigma_rads = sigma_interpolation * cell_size_rads  # sigma for the gaussian interpolation\n",
    "min_station_pixel_distance_km = 86  # minimal distance between station and pixel in km\n",
    "hdf5_in_put_file_path = \"Data/Displacements_min_mainshock_mag=6_min_stations_per_main_shock=3_regression=True_min_after_shock_mag=2.5_after_shock_time_window=45_n_days_before_mainshock=1_n_days_after_mainshock=1_min_days_between_mainshocks=30_grid_size_km=250.hdf5\"  #Path to the HDF5 output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175167db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Global variables:\n",
    "n_seq_init = 0  # Number of sequences processed\n",
    "n_seq_discarded = 0  # Number of sequences discarded\n",
    "soft_labels = False  ## smoothed labels (smoothed over space)\n",
    "regression = False  ## regression instead of classification\n",
    "elasticity = True  # Thin 2D elastic sheet model for interpolating GPS data\n",
    "hdf5_out_put_file_path = (\n",
    "    f\"Data/Interpolated_Data_reg={regression}_soft_labels={soft_labels}_elasticity={elasticity}_min_mainshock_mag=6_min_stations_per_main_shock=3_min_after_shock_mag=4_after_shock_time_window=45_n_days_before_mainshock=1_n_days_after_mainshock=1.hdf5\")  #Path to the HDF5 output file\n",
    "\n",
    "\n",
    "# Add these lists to store the locations and magnitudes of the main shocks\n",
    "main_shock_locations = []\n",
    "main_shock_magnitudes = []\n",
    "\n",
    "def process_main_shock_data(hdf5_file_path, output_path):\n",
    "    \"\"\"Process main shocks data to generate interpolated displacement maps.\"\"\"\n",
    "    global main_shock_locations, main_shock_magnitudes\n",
    "    with h5py.File(hdf5_file_path, 'r') as file:\n",
    "        for id_seq in file.keys():\n",
    "            main_shock_location = file[id_seq].attrs['main_shock_location']\n",
    "            main_shock_magnitude = file[id_seq].attrs['main_shock_magnitude']\n",
    "            main_shock_locations.append(main_shock_location)\n",
    "            main_shock_magnitudes.append(main_shock_magnitude)\n",
    "            process_single_main_shock(file[id_seq], output_path, id_seq)\n",
    "\n",
    "def plot_main_shocks(main_shock_locations = main_shock_locations, main_shock_magnitudes = main_shock_magnitudes):\n",
    "\n",
    "    \"\"\"Plot all main shocks with varying color depending on the intensity and show a bar plot of count of main shocks by magnitude intervals.\"\"\"\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 10))  # Adjusted size to accommodate both plots\n",
    "\n",
    "    # First subplot for the map\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "    ax1.coastlines()\n",
    "\n",
    "    # Convert the magnitudes to colors\n",
    "    magnitudes_norm = (main_shock_magnitudes - np.min(main_shock_magnitudes)) / (np.max(main_shock_magnitudes) - np.min(main_shock_magnitudes))\n",
    "    colors = plt.cm.viridis(magnitudes_norm)\n",
    "\n",
    "    # Plot the main shocks\n",
    "    for location, color in zip(main_shock_locations, colors):\n",
    "        ax1.plot(location[1], location[0], 'x', color=color, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add a colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=np.min(main_shock_magnitudes), vmax=np.max(main_shock_magnitudes)))\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, ax=ax1, orientation='vertical', label='Main Shock Magnitude')\n",
    "\n",
    "    ax1.set_title('Main Shocks')\n",
    "\n",
    "    # Second subplot for the histogram\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Calculate the bins for magnitude intervals [x, x+0.5]\n",
    "    max_mag = np.ceil(np.max(main_shock_magnitudes) + 0.5)\n",
    "    min_mag = np.floor(np.min(main_shock_magnitudes))\n",
    "    bins = np.arange(min_mag, max_mag, 0.5)\n",
    "\n",
    "    # Calculate histogram\n",
    "    counts, _ = np.histogram(main_shock_magnitudes, bins=bins)\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax2.bar(bins[:-1] + 0.25, counts, width=0.5, color='blue', edgecolor='black')\n",
    "    ax2.set_xticks(bins + 0.25)  # Center labels on bars\n",
    "    ax2.set_xticklabels([f'{bin:.1f}-{bin+0.5:.1f}' for bin in bins])\n",
    "    ax2.set_xlabel('Magnitude Intervals')\n",
    "    ax2.set_ylabel('Number of Main Shocks')\n",
    "    ax2.set_title('Distribution of Main Shocks by Magnitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    picture_name = \"Data/Plots/Main_Shocks.png\"\n",
    "    plt.savefig(picture_name)\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_interpolation_grid(main_shock_location, cell_size_degs, num_cells_half):\n",
    "    min_lat = main_shock_location[0] - num_cells_half * cell_size_degs\n",
    "    max_lat = main_shock_location[0] + num_cells_half * cell_size_degs\n",
    "    min_lon = main_shock_location[1] - num_cells_half * cell_size_degs\n",
    "    max_lon = main_shock_location[1] + num_cells_half * cell_size_degs\n",
    "    n_pixels_lat = 2 * num_cells_half  # Number of discretizations in the latitude direction\n",
    "    n_pixels_lon = n_pixels_lat  # Number of discretizations in the longitude direction (cells)\n",
    "    return min_lat, max_lat, min_lon, max_lon, n_pixels_lat, n_pixels_lon\n",
    "\n",
    "def plot_interpolated_data_and_main_shock(interpolated_data, main_shock_location, min_lat, max_lat, min_lon, max_lon, id_seq, main_shock_date, stations_positions, gps_stations_displacements):\n",
    "\n",
    "\n",
    "     # Create a grid of latitudes and longitudes for the interpolated data\n",
    "    lats = np.linspace(min_lat, max_lat, interpolated_data.shape[0])\n",
    "    lons = np.linspace(min_lon, max_lon, interpolated_data.shape[1])\n",
    "    lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "    # Create a map using Cartopy and plot the vector data\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "\n",
    "    # Extract components for the quiver plot\n",
    "    U = interpolated_data[:, :, 0]  # x-component\n",
    "    V = interpolated_data[:, :, 1]  # y-component\n",
    "\n",
    "    # Plot the vector field using quiver\n",
    "    ax.quiver(lon_grid, lat_grid, U, V, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Plot the main shock location and station positions\n",
    "    ax.plot(main_shock_location[1], main_shock_location[0], 'r*', markersize=15, transform=ccrs.PlateCarree())\n",
    "    ax.scatter(stations_positions[:, 1], stations_positions[:, 0], s=30, c='red', marker='x', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Additional plotting options\n",
    "    plt.title(f'Main Shock ID: {id_seq} on {main_shock_date}')\n",
    "    plt.colorbar(ax.quiver(lon_grid, lat_grid, U, V, transform=ccrs.PlateCarree()), label='Vector Magnitude')\n",
    "    picture_name = f'Data/Plots/Main Shock ID: {id_seq} on {main_shock_date}.png'\n",
    "    plt.savefig(picture_name)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def process_single_main_shock(main_shock_group, output_path, id_seq):\n",
    "    global n_seq_init, n_seq_discarded\n",
    "    n_seq_init += 1\n",
    "    print(f\"Processing main shock {id_seq}...\")\n",
    "    gps_stations_displacements = main_shock_group['gps_stations_displacements'][()]\n",
    "    # For each station, multiply the displacement by the scale factor and sum the displacements\n",
    "    # over the time dimension\n",
    "    ## gps_stations_displacements: (NbStations, NbDays, Displacement(X,Y,Z))\n",
    "    gps_stations_displacements *= scale_factor  ## convert to mm\n",
    "    gps_stations_displacements = gps_stations_displacements.reshape(-1, 3)  ## (NbStations, (X,Y,Z))\n",
    "    gps_stations_positions = main_shock_group['stations_positions'][()]\n",
    "    main_shock_location = main_shock_group.attrs['main_shock_location']\n",
    "    after_shocks_locations = main_shock_group['aftershocks_locations'][()]\n",
    "    after_shocks_locations = after_shocks_locations.reshape(-1, 2)  ## (NbAfterShocks, (X,Y))\n",
    "    main_shock_day = main_shock_group.attrs['main_shock_day']\n",
    "    main_shock_mag = main_shock_group.attrs['main_shock_magnitude']\n",
    "    main_shock_date = main_shock_group.attrs['main_shock_day']\n",
    "    stations_positions = main_shock_group['stations_positions'][()]\n",
    "\n",
    "    # Calculate the interpolation grid\n",
    "    min_lat, max_lat, min_lon, max_lon, n_pixels_lat, n_pixels_lon = utilities.calculate_interpolation_grid(\n",
    "        main_shock_location, cell_size_degs, int(num_cells / 2)\n",
    "    )\n",
    "\n",
    "  \n",
    "    # labels\n",
    "    labels = np.zeros((n_pixels_lat, n_pixels_lon))\n",
    "    # discretize the aftershocks \n",
    "    aftershocks_rows = ((after_shocks_locations[:, 0] - min_lat) / cell_size_degs).astype('int')\n",
    "    aftershocks_cols = ((after_shocks_locations[:, 1] - min_lon) / cell_size_degs).astype('int')\n",
    "    # mask to make sure no event is outside the grid\n",
    "    aftershocks_mask = (aftershocks_rows < n_pixels_lat) & (aftershocks_rows >= 0) & (\n",
    "            aftershocks_cols < n_pixels_lon) & (\n",
    "                               aftershocks_cols >= 0)\n",
    "    aftershocks_rows = aftershocks_rows[aftershocks_mask]\n",
    "    aftershocks_cols = aftershocks_cols[aftershocks_mask]\n",
    "    # Metadata on aftershocks inside the grid for the plots\n",
    "    grid_after_shocks_locations = after_shocks_locations[aftershocks_mask]\n",
    "    grid_after_shocks_magnitudes = main_shock_group['aftershocks_magnitudes'][()][aftershocks_mask]\n",
    "    if aftershocks_mask.sum() == 0:\n",
    "        n_seq_discarded += 1\n",
    "        print('Skipping:', id_seq, 'with no aftershocks inside the grid')\n",
    "        return\n",
    "\n",
    "    if not regression:\n",
    "        if soft_labels:\n",
    "            utilities.create_classification_soft_labels(labels, aftershocks_rows, aftershocks_cols, cell_size_rads,\n",
    "                                                        sigma_softlabels * cell_size_rads)\n",
    "        else:\n",
    "            labels[aftershocks_rows, aftershocks_cols] = 1\n",
    "    else:\n",
    "        seismic_moments = 10 ** (\n",
    "                1.5 * grid_after_shocks_magnitudes + 6.07)  # aftershocks magnitudes converted to their seismic moments\n",
    "        if soft_labels:\n",
    "            utilities.create_regression_soft_labels(labels, seismic_moments,\n",
    "                                                    aftershocks_rows, aftershocks_cols, cell_size_rads,\n",
    "                                                    sigma_softlabels * cell_size_rads)\n",
    "        else:\n",
    "         \n",
    "            np.add.at(labels, (aftershocks_rows, aftershocks_cols),\n",
    "                      seismic_moments)  # add the seismic moments to the grid (sum of seismic moments in case of multiple aftershocks in the same pixel)\n",
    "          \n",
    "\n",
    "    # The grid of interpolated displacements: channel shape (X,Y,Z, distance pixel-MS, flag to indicate if the pixel is valid or not)\n",
    "    interpolated_displacements = np.zeros((n_pixels_lat, n_pixels_lon,\n",
    "                                           5))\n",
    "    if elasticity:\n",
    "        try:\n",
    "            gps_stations_displacements_means = gps_stations_displacements.mean(axis=0)\n",
    "            gps_stations_displacements_stds = gps_stations_displacements.std(axis=0)\n",
    "            gps_stations_displacements_standardized = (\n",
    "                                                              gps_stations_displacements - gps_stations_displacements_means) / gps_stations_displacements_stds\n",
    "            # gps_stations_displacements_standardized = zscore(gps_stations_displacements, axis=0) # Standardize the displacements\n",
    "            automatic_reg_factor = 2  #minimal_distances[id]/cell_size_km\n",
    "\n",
    "            utilities.elasticity_interpolation(\n",
    "                interpolated_displacements,\n",
    "                np.pi * main_shock_location / 180,\n",
    "                np.pi * gps_stations_positions / 180,\n",
    "                gps_stations_displacements_standardized,\n",
    "                n_pixels_lat, n_pixels_lon,\n",
    "                np.pi * min_lat / 180,\n",
    "                np.pi * min_lon / 180,\n",
    "                cell_size_rads,\n",
    "                sigma_rads,\n",
    "                min_station_pixel_distance_km,\n",
    "                reg_factor=automatic_reg_factor,\n",
    "                index_ratio=0.8)\n",
    "\n",
    "            interpolated_displacements[:, :, :2] *= gps_stations_displacements_stds[:2]\n",
    "            interpolated_displacements[:, :, :2] += gps_stations_displacements_means[:2]\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    else:\n",
    "        utilities.interpolate_displacements(\n",
    "            interpolated_displacements,\n",
    "            np.pi * main_shock_location / 180,\n",
    "            np.pi * gps_stations_positions / 180,\n",
    "            gps_stations_displacements,\n",
    "            n_pixels_lat, n_pixels_lon,\n",
    "            np.pi * min_lat / 180,\n",
    "            np.pi * min_lon / 180,\n",
    "            cell_size_rads,\n",
    "            sigma_rads,\n",
    "            min_station_pixel_distance_km,\n",
    "        )\n",
    "    #Save the interpolated data and labels to the output file\n",
    "    save_interpolated_data(interpolated_displacements, labels, output_path, id_seq, main_shock_day, main_shock_mag,\n",
    "                           main_shock_location, grid_after_shocks_locations, grid_after_shocks_magnitudes,\n",
    "                           gps_stations_positions)\n",
    "\n",
    "    gps_stations_displacements = main_shock_group['gps_stations_displacements'][()]\n",
    "    print(main_shock_magnitudes)\n",
    "    plot_interpolated_data_and_main_shock(interpolated_displacements, main_shock_location, min_lat, max_lat, min_lon, max_lon, id_seq, main_shock_date, stations_positions, gps_stations_displacements)\n",
    "    print(main_shock_magnitudes)\n",
    "    #Save the interpolated data and labels to the output file\n",
    "    save_interpolated_data(interpolated_displacements, labels, output_path, id_seq, main_shock_day, main_shock_mag,\n",
    "                           main_shock_location, grid_after_shocks_locations, grid_after_shocks_magnitudes,\n",
    "                           gps_stations_positions)\n",
    "    print(main_shock_magnitudes)\n",
    "\n",
    "\n",
    "def save_interpolated_data(interpolated_data, labels, output_path, main_shock_id, main_shock_day, main_shock_mag,\n",
    "                           main_shock_location, grid_after_shocks_locations, grid_after_shocks_magnitudes,\n",
    "                           gps_stations_positions):\n",
    "    with h5py.File(output_path, 'a') as f:\n",
    "        if str(main_shock_id) in f:\n",
    "            del f[str(main_shock_id)]\n",
    "        grp = f.create_group(str(main_shock_id))\n",
    "        grp.attrs['main_shock_day'] = main_shock_day\n",
    "        grp.attrs['main_shock_magnitude'] = main_shock_mag\n",
    "        # For the plots\n",
    "        grp.attrs['main_shock_location'] = main_shock_location\n",
    "\n",
    "        grp.create_dataset('interpolated_displacement', data=interpolated_data)\n",
    "        grp.create_dataset('labels', data=labels)\n",
    "        # Metadata for the plots\n",
    "        grp.create_dataset('grid_after_shocks_locations', data=grid_after_shocks_locations)\n",
    "        grp.create_dataset('grid_after_shocks_magnitudes', data=grid_after_shocks_magnitudes)\n",
    "        grp.create_dataset('gps_station_positions', data=gps_stations_positions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_gps_stations_from_csv(csv_file_path = \"Data/ngl_list.csv\"):\n",
    "    # Read the CSV file\n",
    "    gps_data = pd.read_csv(csv_file_path, sep= \" \" )\n",
    "    print(gps_data.head())\n",
    "\n",
    "    # Extract coordinates\n",
    "    latitudes = gps_data['lat']\n",
    "    longitudes = gps_data['lon']\n",
    "\n",
    "    # Create a map projection using Cartopy\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax.coastlines()  # Draw coastlines for reference\n",
    "\n",
    "    # Plotting GPS stations\n",
    "    ax.set_extent([122, 154, 24, 46], crs=ccrs.PlateCarree())\n",
    "    scatter = ax.scatter(longitudes, latitudes, color='dodgerblue', s=40, marker='o', edgecolor='black', label='GPS Stations', transform=ccrs.Geodetic())\n",
    "\n",
    "    # Optional: Add legend and gridlines for better readability\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.gridlines(draw_labels=True)\n",
    "\n",
    "    plt.title('Map of GPS Stations')\n",
    "    picture_name = \"Data/Plots/GPS_Stations.png\"\n",
    "    plt.savefig(picture_name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_gps_stations_from_csv()\n",
    "# Main\n",
    "def main():\n",
    "    process_main_shock_data(hdf5_in_put_file_path, hdf5_out_put_file_path)\n",
    "    print(main_shock_magnitudes)\n",
    "    plot_main_shocks()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('Number of sequences processed:', n_seq_init)\n",
    "    print('Number of sequences discarded:', n_seq_discarded)\n",
    "    print('Number of sequences kept:', n_seq_init - n_seq_discarded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1289c012861c9d",
   "metadata": {},
   "source": [
    "# Functions to build displacement maps and labels for each main shock in input HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soft_labels = True  ## smoothed labels (smoothed over space)\n",
    "regression = True  ## regression instead of classification\n",
    "elasticity = True  # Thin 2D elastic sheet model for interpolating GPS data\n",
    "hdf5_out_put_file_path = (\n",
    "    f\"Data/Interpolated_Data_reg={regression}_soft_labels={soft_labels}_elasticity={elasticity}_min_mainshock_mag=6_min_stations_per_main_shock=3_min_after_shock_mag=4_after_shock_time_window=45_n_days_before_mainshock=1_n_days_after_mainshock=1.hdf5\")  #Path to the HDF5 output file\n",
    "def main():\n",
    "    process_main_shock_data(hdf5_in_put_file_path, hdf5_out_put_file_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('Number of sequences processed:', n_seq_init)\n",
    "    print('Number of sequences discarded:', n_seq_discarded)\n",
    "    print('Number of sequences kept:', n_seq_init - n_seq_discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global storage for all aftershocks\n",
    "global_aftershocks = []\n",
    "\n",
    "def process_main_shock_data(hdf5_file_path, output_path):\n",
    "    global main_shock_locations, main_shock_magnitudes, global_aftershocks\n",
    "    with h5py.File(hdf5_file_path, 'r') as file:\n",
    "        for id_seq in file.keys():\n",
    "            main_shock_group = file[id_seq]\n",
    "            aftershocks_locations = main_shock_group['aftershocks_locations'][()]\n",
    "            aftershocks_magnitudes = main_shock_group['aftershocks_magnitudes'][()]\n",
    "\n",
    "            # Append each aftershock's location and magnitude to the global list\n",
    "            for location, magnitude in zip(aftershocks_locations, aftershocks_magnitudes):\n",
    "                global_aftershocks.append((location, magnitude))\n",
    "\n",
    "\n",
    "def aggregate_aftershocks(grid_size_km):\n",
    "    # Aggregate magnitudes by location\n",
    "    location_magnitude_map = defaultdict(float)\n",
    "    earth_radius_km = 6371  # Approximate radius of Earth in kilometers\n",
    "\n",
    "    for (lat, lon), mag in global_aftershocks:\n",
    "        # Convert lat, lon to a grid cell\n",
    "        grid_lat = int(lat / grid_size_km * (180 / np.pi * earth_radius_km))\n",
    "        grid_lon = int(lon / grid_size_km * (180 / np.pi * earth_radius_km))\n",
    "        location_magnitude_map[(grid_lat, grid_lon)] += mag\n",
    "\n",
    "    return location_magnitude_map\n",
    "\n",
    "\n",
    "def plot_aftershocks(location_magnitude_map):\n",
    "    earth_radius_km = 6371\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    \n",
    "\n",
    "    # Plot each aftershock\n",
    "    for (grid_lat, grid_lon), magnitude in location_magnitude_map.items():\n",
    "        # Convert grid cell back to lat, lon\n",
    "        lat = grid_lat * grid_size_km / (180 / np.pi * earth_radius_km)\n",
    "        lon = grid_lon * grid_size_km / (180 / np.pi * earth_radius_km)\n",
    "        ax.plot(lon, lat, 'ro', markersize=magnitude ** 0.5, alpha=0.6)\n",
    "\n",
    "    ax.coastlines()\n",
    "\n",
    "    plt.title('Cumulative Magnitudes of Aftershocks')\n",
    "    picture_name = \"Data/Plots/Aftershocks.png\"\n",
    "    plt.savefig(picture_name)\n",
    "    plt.show()\n",
    "\n",
    "process_main_shock_data(hdf5_in_put_file_path, hdf5_out_put_file_path)\n",
    "location_magnitude_map = aggregate_aftershocks(grid_size_km)\n",
    "plot_aftershocks(location_magnitude_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70d71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecac92c-bc62-42ed-b073-b7b1ce02e93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
